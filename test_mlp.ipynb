{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa57412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniTorchModel(\n",
      "  (layer1): Linear(in_features=2, out_features=3, bias=True),\n",
      "  (layer2): Linear(in_features=3, out_features=1, bias=True),\n",
      ")\n",
      "--------------------------------------------------\n",
      "MiniTorch Model Output:\n",
      "tensor([[0.5692]], requires_grad=True)\n",
      "MiniTorch Model Parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0624 -0.5109  0.3155]\n",
      " [ 0.6344  0.3436 -0.4453]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0068  0.2181 -0.1573], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0887]\n",
      " [-0.3915]\n",
      " [-0.5667]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3652], requires_grad=True)\n",
      "--------------------------------------------------\n",
      "tensor([[1. 1.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1. 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import minitorch\n",
    "import minitorch.nn as nn\n",
    "from minitorch.nn import Linear, Module\n",
    "from minitorch import Tensor\n",
    "from minitorch.nn.parameter import Parameter\n",
    "\n",
    "class MiniTorchModel(Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.layer1 = Linear(in_feat, 3)\n",
    "        self.layer2 = Linear(3, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "minitorch_model = MiniTorchModel(2, 1)\n",
    "print(minitorch_model)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "input_tensor = Tensor([[1.0, 1.0]])\n",
    "\n",
    "out_minitorch = minitorch_model(input_tensor)\n",
    "\n",
    "print(\"MiniTorch Model Output:\")\n",
    "print(out_minitorch)\n",
    "\n",
    "print(\"MiniTorch Model Parameters:\")\n",
    "for param in minitorch_model.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "# Test Tensor\n",
    "t = Tensor([[1.0, 1.0]])\n",
    "print(t)\n",
    "\n",
    "p = Parameter(Tensor([[1.0, 1.0]]))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fed030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniTorchModel(\n",
      "  (layer1): Linear(in_features=2, out_features=3, bias=True),\n",
      "  (layer2): Linear(in_features=3, out_features=1, bias=True),\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.4798  0.5338  0.328 ]\n",
      " [-0.5145  0.1215 -0.2622]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2228 -0.2896 -0.3408], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3202]\n",
      " [-0.1298]\n",
      " [-0.106 ]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2885], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from minitorch.nn import Linear, Module\n",
    "from minitorch import Tensor\n",
    "from minitorch.nn.parameter import Parameter\n",
    "\n",
    "class MiniTorchModel(Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.layer1 = Linear(in_feat, 3)\n",
    "        self.layer2 = Linear(3, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "minitorch_model = MiniTorchModel(2, 1)\n",
    "print(minitorch_model)\n",
    "\n",
    "print(minitorch_model.layer1.weight)\n",
    "print(minitorch_model.layer1.bias)\n",
    "\n",
    "print(minitorch_model.layer2.weight)\n",
    "print(minitorch_model.layer2.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e057f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.4798  0.5338  0.328 ]\n",
      " [-0.5145  0.1215 -0.2622]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2228 -0.2896 -0.3408], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3202]\n",
      " [-0.1298]\n",
      " [-0.106 ]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2885], requires_grad=True)]\n",
      "--------------------------------------------------\n",
      "<bound method Module.parameters of MiniTorchModel(\n",
      "  (layer1): Linear(in_features=2, out_features=3, bias=True),\n",
      "  (layer2): Linear(in_features=3, out_features=1, bias=True),\n",
      ")>\n",
      "None\n",
      "tensor(0.0)\n"
     ]
    }
   ],
   "source": [
    "print(minitorch_model.parameters())\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "print(minitorch_model.parameters)\n",
    "print(minitorch_model.zero_grad())\n",
    "\n",
    "print(minitorch_model.layer1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8943b849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (layer1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (layer2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Torch Model Output:\n",
      "tensor([[-0.3047]], grad_fn=<AddmmBackward0>)\n",
      "Torch Model Parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.6296,  0.5635],\n",
      "        [-0.6932, -0.4749],\n",
      "        [ 0.0302, -0.0009]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1758,  0.5085, -0.4160], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1787,  0.1831,  0.0106]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0648], requires_grad=True)\n",
      "--------------------------------------------------\n",
      "tensor([[1., 1.]])\n",
      "None\n",
      "False\n",
      "tensor([[1., 1.]], requires_grad=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m z = torch.tensor([[\u001b[32m1.0\u001b[39m] * \u001b[32m2\u001b[39m], requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(z)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m p = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(p)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\anaconda3\\envs\\torchenv\\Lib\\site-packages\\torch\\nn\\parameter.py:49\u001b[39m, in \u001b[36mParameter.__new__\u001b[39m\u001b[34m(cls, data, requires_grad)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.Tensor._make_subclass(\u001b[38;5;28mcls\u001b[39m, data, requires_grad)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Path for custom tensors: set a flag on the instance to indicate parameter-ness.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m t = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m().requires_grad_(requires_grad)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreating a Parameter from an instance of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequires that detach() returns an instance of the same type, but return \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mits __torch_dispatch__() implementation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TorchModel(torch.nn.Module):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(in_feat, 3)\n",
    "        self.layer2 = torch.nn.Linear(3, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "torch_model = TorchModel(2, 1)\n",
    "out_torch = torch_model(torch.tensor([[1.0] * 2]))\n",
    "\n",
    "\n",
    "print(torch_model)\n",
    "print('-' * 50)\n",
    "\n",
    "\n",
    "print(\"Torch Model Output:\")\n",
    "print(out_torch)\n",
    "\n",
    "print(\"Torch Model Parameters:\")\n",
    "for param in torch_model.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "t = torch.tensor([[1.0] * 2])\n",
    "print(t)\n",
    "print(t.grad)\n",
    "print(t.requires_grad)\n",
    "\n",
    "z = torch.tensor([[1.0] * 2], requires_grad=True)\n",
    "print(z)\n",
    "\n",
    "p = torch.nn.Parameter(1.0)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward output: tensor([[11.1]], requires_grad=True)\n",
      "Gradient of w:\n",
      " [[1.]\n",
      " [2.]]\n",
      "Gradient of b:\n",
      " [1.]\n"
     ]
    }
   ],
   "source": [
    "from minitorch.nn import Parameter\n",
    "\n",
    "x = Tensor([[1.0, 2.0]], requires_grad=False)\n",
    "w = Parameter(Tensor([[3.0], [4.0]]))  # shape: (2,1)\n",
    "b = Parameter(Tensor([0.1]))  # shape: (1,)\n",
    "\n",
    "y = x @ w + b\n",
    "print(\"Forward output:\", y)\n",
    "\n",
    "y.backward()\n",
    "print(\"Gradient of w:\\n\", w.grad)\n",
    "print(\"Gradient of b:\\n\", b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b704c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999\n"
     ]
    }
   ],
   "source": [
    "from minitorch.nn.parameter import Parameter\n",
    "from minitorch.optim import SGD\n",
    "\n",
    "\n",
    "# Dummy example\n",
    "w = Parameter(1.0)  # Initial value\n",
    "w.grad = 0.1        # gradient\n",
    "\n",
    "opt = SGD([w], lr=0.01)\n",
    "opt.step()\n",
    "print(w.data)  # Should be 1.0 - 0.01 * 0.1 = 0.999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7970ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 10\n",
      "Dataset(10)\n",
      "DataLoader length: 4\n",
      "DataLoader(batch_size=3, shuffle=True, dataset_size=10)\n",
      "Batch x: [7, 9, 2]\n",
      "Batch y: [15, 19, 5]\n",
      "Batch x: [3, 8, 5]\n",
      "Batch y: [7, 17, 11]\n",
      "Batch x: [4, 0, 6]\n",
      "Batch y: [9, 1, 13]\n",
      "Batch x: [1]\n",
      "Batch y: [3]\n"
     ]
    }
   ],
   "source": [
    "from minitorch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, xs, ys):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.xs[idx], self.ys[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "# Dummy data\n",
    "xs = [i for i in range(10)]\n",
    "ys = [2 * i + 1 for i in range(10)]\n",
    "\n",
    "\n",
    "dataset = MyDataset(xs, ys)\n",
    "print(\"Dataset length:\", len(dataset))\n",
    "print(dataset)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "print(\"DataLoader length:\", len(loader))\n",
    "print(loader)\n",
    "\n",
    "for xb, yb in loader:\n",
    "    print(\"Batch x:\", list(xb))\n",
    "    print(\"Batch y:\", list(yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510ed403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 109.7702\n",
      "Epoch 2: Loss = 0.6510\n",
      "Epoch 3: Loss = 0.5246\n",
      "Epoch 4: Loss = 0.4940\n",
      "Epoch 5: Loss = 0.4356\n",
      "Epoch 6: Loss = 0.4369\n",
      "Epoch 7: Loss = 0.3475\n",
      "Epoch 8: Loss = 0.3470\n",
      "Epoch 9: Loss = 0.2195\n",
      "Epoch 10: Loss = 0.1942\n"
     ]
    }
   ],
   "source": [
    "from minitorch.nn.parameter import Parameter\n",
    "from minitorch.engine import Tensor\n",
    "from minitorch.optim import SGD\n",
    "\n",
    "# Single-variable linear regression: y = wx + b\n",
    "w = Parameter(Tensor([0.0]))\n",
    "b = Parameter(Tensor([0.0]))\n",
    "\n",
    "def predict(x):\n",
    "    return w.data * x + b.data\n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    return (y_pred - y_true) ** 2\n",
    "\n",
    "optimizer = SGD([w, b], lr=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0.0\n",
    "    for x_batch, y_batch in loader:\n",
    "        for x, y in zip(x_batch, y_batch):\n",
    "            x = Tensor(x)\n",
    "            y = Tensor(y)\n",
    "            y_pred = predict(x)\n",
    "            loss = compute_loss(y_pred, y)\n",
    "\n",
    "            # Manual \"backward\"\n",
    "            grad_y_pred = 2.0 * (y_pred - y)\n",
    "            w.grad = grad_y_pred * x\n",
    "            b.grad = grad_y_pred * 1.0\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    total_loss /= len(loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d5848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
