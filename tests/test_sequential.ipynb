{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ace5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x268b73d3010>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from minitorch import Tensor\n",
    "from minitorch.nn import Sequential, Linear\n",
    "from minitorch.nn import ReLU\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# set seed \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9240487",
   "metadata": {},
   "source": [
    "### Test for minitorch.nn.modules.Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf9b005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): ReLU(),\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True),\n",
      ")\n",
      "Output: tensor([[-1.0889]], requires_grad=True)\n",
      "First layer: Linear(in_features=2, out_features=4, bias=True)\n",
      "After append: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): ReLU(),\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True),\n",
      "  (3): ReLU(),\n",
      ")\n",
      "After insert: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True),\n",
      "  (2): ReLU(),\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True),\n",
      "  (4): ReLU(),\n",
      ")\n",
      "After pop: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True),\n",
      "  (2): ReLU(),\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True),\n",
      ")\n",
      "After setitem: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True),\n",
      "  (2): ReLU(),\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True),\n",
      ")\n",
      "After delitem: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True),\n",
      "  (1): ReLU(),\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build a simple sequential model\n",
    "model = Sequential(\n",
    "    Linear(2, 4),\n",
    "    ReLU(),\n",
    "    Linear(4, 1)\n",
    ")\n",
    "\n",
    "print(\"Sequential model:\")\n",
    "print(model)\n",
    "\n",
    "# Test forward pass\n",
    "x = Tensor([[1.0, 2.0]])\n",
    "out = model(x)\n",
    "print(\"Output:\", out)\n",
    "\n",
    "# Test __getitem__, __setitem__, __delitem__, append, insert, pop\n",
    "print(\"First layer:\", model[0])\n",
    "model.append(ReLU())\n",
    "print(\"After append:\", model)\n",
    "model.insert(1, Linear(2, 2))\n",
    "print(\"After insert:\", model)\n",
    "removed = model.pop()\n",
    "print(\"After pop:\", model)\n",
    "model[0] = Linear(2, 4)\n",
    "print(\"After setitem:\", model)\n",
    "del model[1]\n",
    "print(\"After delitem:\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700bda14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.3967, -0.5398],\n",
      " [ 0.1979, -0.5044],\n",
      " [ 0.6289,  0.0309],\n",
      " [-0.1207, -0.333 ]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3878, -0.062 ,  0.0968, -0.6805], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.068 ,  0.4256, -0.429 , -0.4129]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4798], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Test parameters\n",
    "print(\"Parameters:\")\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d44e5",
   "metadata": {},
   "source": [
    "### Compare with torch.nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9424a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Sequential model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "Output: tensor([[-0.1143]], grad_fn=<AddmmBackward0>)\n",
      "First layer: Linear(in_features=2, out_features=4, bias=True)\n",
      "After append: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "After insert: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (4): ReLU()\n",
      ")\n",
      "After pop: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "After setitem: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "After delitem: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build a similar sequential model in PyTorch\n",
    "model_torch = nn.Sequential(\n",
    "    nn.Linear(2, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "\n",
    "print(\"PyTorch Sequential model:\")\n",
    "print(model_torch)\n",
    "\n",
    "# Test forward pass\n",
    "x_torch = torch.tensor([[1.0, 2.0]])\n",
    "out_torch = model_torch(x_torch)\n",
    "print(\"Output:\", out_torch)\n",
    "\n",
    "# Test __getitem__, __setitem__, __delitem__, append, insert, pop\n",
    "print(\"First layer:\", model_torch[0])\n",
    "model_torch.append(nn.ReLU())\n",
    "print(\"After append:\", model_torch)\n",
    "model_torch.insert(1, nn.Linear(2, 2))\n",
    "print(\"After insert:\", model_torch)\n",
    "removed = model_torch.pop(-1)\n",
    "print(\"After pop:\", model_torch)\n",
    "model_torch[0] = nn.Linear(2, 4)\n",
    "print(\"After setitem:\", model_torch)\n",
    "del model_torch[1]\n",
    "print(\"After delitem:\", model_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6536e15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.5291, -0.1140],\n",
      "        [ 0.0748,  0.6403],\n",
      "        [-0.6560, -0.4452],\n",
      "        [-0.1790, -0.2756]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.6109, -0.4583, -0.3255, -0.4940], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.4777, -0.3311, -0.2061,  0.0185]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1977], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Test parameters\n",
    "print(\"Parameters:\")\n",
    "for param in model_torch.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9cd368",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aae73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial predictions: tensor([[-0.5466],\n",
      " [-0.7812],\n",
      " [-1.0724],\n",
      " [-1.323 ]], requires_grad=True)\n",
      "Epoch 1, Loss: 81.8946\n",
      "Epoch 11, Loss: 0.4743\n",
      "Epoch 21, Loss: 0.3190\n",
      "Epoch 31, Loss: 0.2240\n",
      "Epoch 41, Loss: 0.1646\n",
      "Epoch 51, Loss: 0.1264\n",
      "Epoch 61, Loss: 0.1008\n",
      "Epoch 71, Loss: 0.0819\n",
      "Epoch 81, Loss: 0.0677\n",
      "Epoch 91, Loss: 0.0565\n",
      "Final predictions: tensor([[ 5.2614],\n",
      " [ 4.2943],\n",
      " [10.8556],\n",
      " [ 9.8834]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# MLP using Sequential and training for 10 epochs\n",
    "from minitorch import Tensor\n",
    "from minitorch.nn import Sequential, Linear\n",
    "from minitorch.nn import ReLU, MSELoss\n",
    "from minitorch.optim import SGD\n",
    "\n",
    "# Dummy data: y = x1 + 2*x2\n",
    "X = Tensor([[1.0, 2.0], [2.0, 1.0], [3.0, 4.0], [4.0, 3.0]])\n",
    "y = Tensor([[5.0], [4.0], [11.0], [10.0]])\n",
    "\n",
    "# Build MLP model\n",
    "mlp = Sequential(\n",
    "    Linear(2, 8),\n",
    "    ReLU(),\n",
    "    Linear(8, 1)\n",
    ")\n",
    "\n",
    "criterion = MSELoss()\n",
    "optimizer = SGD(mlp.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Initial predictions:\", mlp(X))\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = mlp(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Final predictions:\", mlp(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc4d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
