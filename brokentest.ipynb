{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11564b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minitorch.nn.parameter import Parameter\n",
    "\n",
    "class BrokenModule:\n",
    "    def __init__(self):\n",
    "        self._parameters = {}\n",
    "        self._modules = {}\n",
    "    \n",
    "    def parameters(self):\n",
    "        params = list(self._parameters.values())\n",
    "        for module in self._modules.values():\n",
    "            params.extend(module.parameters())\n",
    "        return params\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.zero_grad()\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Subclasses must implement the forward method.\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        rep = f\"{self.__class__.__name__}(\\n\"\n",
    "        for name, param in self._parameters.items():\n",
    "            rep += f\"  ({name}): {param},\\n\"\n",
    "        for name, module in self._modules.items():\n",
    "            rep += f\"  ({name}): {module},\\n\"\n",
    "        rep += \")\"\n",
    "        return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72c659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from minitorch.engine import Tensor\n",
    "from minitorch.nn.parameter import Parameter\n",
    "\n",
    "class Linear(BrokenModule):\n",
    "    def __init__(self,in_features, out_features, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        k= 1 / (in_features ** 0.5)\n",
    "        \n",
    "        weight_data = [[random.uniform(-k, k) for _ in range(out_features)] for _ in range(in_features)]\n",
    "        self.weight = Parameter(Tensor(weight_data)) \n",
    "\n",
    "        if bias:\n",
    "            bias_data = [random.uniform(-k, k) for _ in range(out_features)]\n",
    "            self.bias = Parameter(Tensor(bias_data))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, Tensor):\n",
    "            raise TypeError(\"Input must be a Tensor.\")\n",
    "        if x.data.shape[1] != self.in_features:\n",
    "            raise ValueError(f\"Input shape {x.data.shape} does not match expected shape ({x.data.shape[0]}, {self.in_features}).\")\n",
    "        \n",
    "        out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Linear(in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2567097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniTorchModel(\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[ 0.5934  0.2652 -0.3113]\n",
      " [ 0.2123 -0.1907 -0.4582]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5554 -0.1766  0.0723], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3387]\n",
      " [ 0.304 ]\n",
      " [ 0.4305]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.537], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from minitorch.nn import Linear, Module\n",
    "from minitorch import Tensor\n",
    "from minitorch.nn.parameter import Parameter\n",
    "\n",
    "class MiniTorchModel(BrokenModule):\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.layer1 = Linear(in_feat, 3)\n",
    "        self.layer2 = Linear(3, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "minitorch_model = MiniTorchModel(2, 1)\n",
    "print(minitorch_model)\n",
    "\n",
    "print(minitorch_model.layer1.weight)\n",
    "print(minitorch_model.layer1.bias)\n",
    "\n",
    "print(minitorch_model.layer2.weight)\n",
    "print(minitorch_model.layer2.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389feaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "--------------------------------------------------\n",
      "<bound method BrokenModule.parameters of MiniTorchModel(\n",
      ")>\n",
      "None\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(minitorch_model.parameters())\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "print(minitorch_model.parameters)\n",
    "print(minitorch_model.zero_grad())\n",
    "\n",
    "print(minitorch_model.layer1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293c822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
